import pandas as pd
import string


def filter_rows(df, condition, reason):
    """
    :param reason:
    :param df:
    :param condition: boolean, true for row to keep
    :return: filter country_city_codes df
    """
    n_dropped = (condition == False).sum()
    print(f'\nexcluding {n_dropped} locations ({n_dropped / df.shape[0]:.1%}) due to {reason}')
    return df[condition]


def clean_unloc(unloc):
    colidx_to_keep = [1, 2, 3, 4, 7, 10]
    unloc = unloc.iloc[:, colidx_to_keep].copy()
    colnames_dict = dict(zip(colidx_to_keep, ['ccode','loccode','locname','subdiv','status','geocode']))
    unloc.rename(columns=colnames_dict, inplace=True)
    print(f'head after import:\n{unloc.head()}')

    status_to_exclude = ['RQ','RR','QQ','UR','XX']
    filter_status = (~unloc.status.isin(status_to_exclude))

    unloc = filter_rows(unloc, condition=filter_status, reason='invalid status')

    print(f'\nNAs:\n{unloc.isna().sum()}')
    unloc = filter_rows(unloc, condition=(~unloc.status.isna()), reason='missing status')
    unloc = filter_rows(unloc, condition=(~unloc.loccode.isna()), reason='missing loccode')
    unloc = filter_rows(unloc, condition=(~unloc.ccode.isna()), reason='missing ccode')
    unloc = filter_rows(unloc, condition=(~unloc.ccode.isin(['XZ'])), reason='undefined ccode XZ')

    unloc.insert(2, 'citycode', unloc.ccode + unloc.loccode)

    return unloc


def prepare_unloc(unloc_files):
    if not isinstance(unloc_files, list):
        unloc_files = [unloc_files]
    city_codes = pd.DataFrame()
    for file_path in unloc_files:
        print(file_path)
        unloc_raw = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)
        unloc_tmp = clean_unloc(unloc_raw)
        city_codes = pd.concat([city_codes, unloc_tmp])

    # cleaning
    city_codes = city_codes[['ccode', 'locname', 'loccode']]
    city_codes = city_codes.rename(columns={'ccode': 'country_code', 'locname': 'city', 'loccode': 'city_code'})
    city_codes = city_codes.groupby(['country_code', 'city']).city_code.first().reset_index()

    return city_codes


def prepare_ccodes(ccode_file):
    country = pd.read_csv(ccode_file, names=['cname', 'ccode'], header=0)
    filter_cname = (~country.cname.isin(['Namibia', 'Bouvet Island']))
    country = country[filter_cname]

    country.rename(columns={'cname': 'country', 'ccode': 'country_code'}, inplace=True)

    country.loc[country.country_code == 'KR', 'country'] = 'South Korea'
    country.loc[country.country_code == 'RU', 'country'] = 'Russia'
    country.loc[country.country_code == 'IR', 'country'] = 'Iran'
    country.loc[country.country_code == 'VN', 'country'] = 'Vietnam'
    country.loc[country.country_code == 'TZ', 'country'] = 'Tanzania'
    country.loc[country.country_code == 'BO', 'country'] = 'Bolivia'
    country.loc[country.country_code == 'TW', 'country'] = 'Taiwan'
    country.loc[country.country_code == 'VE', 'country'] = 'Venezuela'
    country.loc[country.country_code == 'SY', 'country'] = 'Syria'
    country.loc[country.country_code == 'CZ', 'country'] = 'Czechia'
    country.loc[country.country_code == 'LA', 'country'] = 'Laos'
    country.loc[country.country_code == 'MD', 'country'] = 'Moldova'
    country.loc[country.country_code == 'MK', 'country'] = 'Macedonia'
    country.loc[country.country_code == 'TW', 'country'] = 'Taiwan'
    # country = country.append({'country': 'Namibia', 'country_code': 'NA'}, ignore_index=True)
    country.loc[country.country_code == 'BN', 'country'] = 'Brunei'
    country.loc[country.country_code == 'FM', 'country'] = 'Micronesia'
    country.loc[country.country_code == 'RE', 'country'] = 'Reunion'
    country.loc[country.country_code == 'VA', 'country'] = 'Vatican City'
    country.loc[country.country_code == 'FK', 'country'] = 'Falkland Islands'

    obs_per_country = country.groupby('country').size()
    obs_per_country
    if (obs_per_country > 1).sum() != 0:
        raise Exception('Country name not unique!')

    country

    return country


def check_ccode_loccode(ccodes, unloc):

    unloc_check = pd.DataFrame({
       'country_code': unloc.country_code.unique(),
        'country_city_codes': 1
    })
    # print(unloc_check.isna().sum())
    ccode_loccode_check = ccodes.merge(unloc_check, how='outer', on='country_code')

    # ccode_loccode_check[ccode_loccode_check.isnull().any(axis=1)]
    # unloc_check[unloc_check.ccode.str.contains('NA')]
    # country_city_codes[country_city_codes.ccode=='XZ']
    # ccodes[ccodes.cname=='Namibia']

    if ccode_loccode_check.isna().sum().sum() != 0:
        raise Exception('Missmatch between ccodes and country_city_codes. Investigate both files.')
    else:
        return 'ok'


def filter_per_group(df, id_col, filter_col, filter_fct):
    idx = df.groupby(id_col)[filter_col].transform(filter_fct) == df[filter_col]
    return df[idx]


def prepare_world_cities(world_city_file):
    cities = pd.read_csv(world_city_file)
    (cities.city + '_' + cities.country).nunique() / cities.shape[0]

    # cities['city_country'] = cities.city +'_'+ cities.country

    # rows_per_citycountry = cities.groupby('city_country').size()
    # rows_per_citycountry[rows_per_citycountry > 1]

    cities = filter_per_group(
        df=cities,
        id_col=['city', 'country'],
        filter_col='population',
        filter_fct=max)

    # rename

    # inspection
    # country[country.country.str.contains('falk', case=False)]
    # country.loc[country.ccode == 'KO']

    cities.loc[cities.country == 'Korea, South', 'country'] = 'South Korea'
    cities.loc[cities.country.str.contains('congo', case=False), 'country'] = 'Congo'
    cities.loc[cities.country.str.contains('ivoire', case=False), 'country'] = "CÃ´te d'Ivoire"
    cities.loc[cities.country.str.contains('bosnia', case=False), 'country'] = "Bosnia and Herzegovina"
    cities.loc[cities.country.str.contains('bahamas', case=False), 'country'] = "Bahamas"
    cities.loc[cities.country.str.contains('verde', case=False), 'country'] = "Cape Verde"
    cities.loc[cities.country.str.contains('tobago', case=False), 'country'] = "Trinidad and Tobago"
    cities.loc[cities.country.str.contains('Gambia', case=False), 'country'] = "Gambia"
    cities.loc[cities.country.str.contains('tome', case=False), 'country'] = "Sao Tome and Principe"
    cities.loc[cities.country.str.contains('Grenadines', case=False), 'country'] = "Saint Vincent and the Grenadines"
    cities.loc[cities.country.str.contains('Antigua', case=False), 'country'] = "Antigua and Barbuda"
    cities.loc[cities.country.str.contains('Macau', case=False), 'country'] = "Macao"
    cities.loc[cities.country.str.contains('Micronesia', case=False), 'country'] = "Micronesia"
    cities.loc[cities.country.str.contains('Reunion', case=False), 'country'] = "Reunion"
    cities.loc[cities.country.str.contains('Isle of Man', case=False), 'country'] = "Isle of Man"
    cities.loc[cities.country.str.contains('falkland', case=False), 'country'] = "Falkland Islands"

    return cities


def merge_country_codes_on_cities(cities, country):
    # check join country code in cities
    cities_check = pd.DataFrame({
        'country_name': cities.country.unique(),
        'in_cities': 1
    })
    cities_check

    country_check = pd.DataFrame({
        'country_name': country.country.unique(),
        'in_countries': 1
    })

    check = cities_check.merge(country_check, how='left', on='country_name')
    check.in_cities.isna().sum()
    check.in_countries.isna().sum()
    check[check.in_countries.isna()]

    cities = cities.merge(country, how='left', on='country')

    cities_no_countrycode = cities[cities.country_code.isna()].country.unique()
    print(cities.country.nunique())
    print(cities.shape)
    print(len(cities_no_countrycode))
    if len(cities_no_countrycode) == 7:
        cities = cities.loc[(~cities.country_code.isna()), ]
    else:
        raise Exception('Eliminating more countries than expected')
    print(cities.shape)
    print(cities.country.nunique())

    print(f'\nNAs in cities:\n{cities.isna().sum()}')

    # remove dubplicate cities
    cities = cities[cities.city != 'Darhan']
    cities = cities[cities.city != 'Crato']

    # check if city country unique
    (cities.country + cities.city).nunique()
    obs_per_citycountry = cities.groupby(['country', 'city']).size()
    if len(obs_per_citycountry[obs_per_citycountry > 1]) != 0:
        raise Exception('city country not unique!')

    return cities


def merge_city_codes(cities, city_codes):
    cities_check = cities[['country_code', 'city']].copy()
    cities_check['in_cities'] = 1
    cities_check = cities_check.merge(city_codes, how='left', on=['country_code', 'city'])

    obs_per_citycountry = cities_check.groupby(['country_code', 'city']).size()
    obs_per_citycountry[obs_per_citycountry > 1]
    print('cities_check', cities_check.shape)
    print('cities', cities.shape)

    # merge city codes
    if len(obs_per_citycountry[obs_per_citycountry > 1]) == 0:
        cities = cities.merge(city_codes, how='left', on=['country_code', 'city'])
        print('cities', cities.shape)

    else:
        raise Exception('Can not merge city_codes in cities. Keys ambigiouse')

    cities['cc_code'] = cities.country_code + '-' + cities.city_code

    cities = cities[['cc_code', 'city', 'city_code', 'country', 'country_code', 'lat', 'lng', 'population']]

    # create artificial city codes
    print('creating artificial city codes')
    cc_codes = cities[~cities.cc_code.isna()].cc_code.to_list()
    for idx, row in cities[cities.city_code.isna()].iterrows():
        city_name_tmp_clean = row.city.translate(str.maketrans('', '', string.punctuation)).replace(' ', '').upper()
        city_code_tmp = city_name_tmp_clean[0:3]
        cc_code_tmp = row.country_code + '-' + city_code_tmp
        if cc_code_tmp not in cc_codes and len(city_name_tmp_clean) >= 3:
            cc_codes.append(cc_code_tmp + '-X')
            cities.loc[idx, 'cc_code'] = cc_code_tmp + '-X'
            cities.loc[idx, 'city_code'] = city_code_tmp + '-X'
        else:
            if len(city_name_tmp_clean) >= 4:
                city_code_tmp = city_name_tmp_clean[0:2] + city_name_tmp_clean[3]
                cc_code_tmp = row.country_code + '-' + city_code_tmp
                if cc_code_tmp not in cc_codes:
                    cc_codes.append(cc_code_tmp + '-X')
                    cities.loc[idx, 'cc_code'] = cc_code_tmp + '-X'
                    cities.loc[idx, 'city_code'] = city_code_tmp + '-X'

                else:
                    pass
            else:
                pass

    if cities.cc_code.isna().sum() <= 278:
        cities = cities[~cities.cc_code.isna()]
    else:
        raise Exception('More more missing cc_codes than expected!')

    print('done')

    return cities


def enrich_cities(cities, country_codes, city_codes):

    cities = merge_country_codes_on_cities(cities, country_codes)

    cities = merge_city_codes(cities, city_codes)

    return cities


def clean_citytemp():
    print('clean_citytemp')


cleaner = globals()['clean_citytemp']
cleaner()
